{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['#justiceforSushanthSinghRajput', '#ModiStrongestPmEver', '#WeStandWithINDIANArmy', '#galwanvalleyclash', '#StopLateralEntry', 'Taiwan', 'ChineseBhagao RoposoApnao', 'I SUPPORT TIGER SHROFF', 'Photo of the Day', 'Rs 2,400']\nenglish\nenglish\nenglish\nenglish\nenglish\nenglish\nenglish\nenglish\nenglish\nother\nenglish\nenglish\nenglish\nother\nenglish\nenglish\nenglish\nenglish\nenglish\nenglish\nNegative\n[0.46779633]\n"
    }
   ],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import functools\n",
    "import os\n",
    "import io\n",
    "\n",
    "from twitter_scraper import get_tweets\n",
    "from requests_html import HTML, HTMLSession\n",
    "from langdetect import detect\n",
    "\n",
    "\n",
    "def clean_tweet(tweet): \n",
    "        return ''.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|(\\[\\])\", \" \", tweet))\n",
    "\n",
    "\n",
    "def review_encode(s):\n",
    "    encoded = [1]\n",
    "    for word in s:\n",
    "        if word.lower() in word_index:\n",
    "            encoded.append(word_index[word.lower()])\n",
    "        else:\n",
    "            encoded.append(2)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "word_index = tf.keras.datasets.imdb.get_word_index()\n",
    "\n",
    "\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "reverse_word_index = dict([(value,key) for (key,value) in word_index.items()])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "session = HTMLSession()\n",
    "\n",
    "\n",
    "def get_trends():\n",
    "    trends = []\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8\",\n",
    "        \"X-Twitter-Active-User\": \"yes\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"Accept-Language\": \"en-US\",\n",
    "    }\n",
    "\n",
    "    html = session.get(\"https://twitter.com/i/trends\", headers=headers)\n",
    "    html = html.json()[\"module_html\"]\n",
    "\n",
    "    html = HTML(html=html, url=\"bunk\", default_encoding=\"utf-8\")\n",
    "\n",
    "    for trend_item in html.find(\"li\"):\n",
    "        trend_text = trend_item.attrs[\"data-trend-name\"]\n",
    "\n",
    "        trends.append(trend_text)\n",
    "\n",
    "    return trends\n",
    "\n",
    "\n",
    "var = get_trends()\n",
    "print(var)\n",
    "filetag = io.open('test_tag.txt', \"w\", encoding=\"utf-8\")\n",
    "for i in var:\n",
    "    tag = i \n",
    "    filetag.write(tag)\n",
    "filetag.close()\n",
    "\n",
    "\n",
    "file1 = io.open('test1.txt', \"w\", encoding=\"utf-8\")\n",
    "for tweet in get_tweets(var[0], pages=1): \n",
    "    text = tweet['text']\n",
    "    text = clean_tweet(text)\n",
    "    if detect(tweet['text']) == 'en':\n",
    "        print('english',end='\\n')\n",
    "        file1.write(text)\n",
    "        #print(tweet)\n",
    "    else :\n",
    "        print(\"other\",end='\\n')\n",
    "    \n",
    "file1.close()\n",
    "\n",
    "\n",
    "#FILE OPENS\n",
    "\n",
    "os.system('cmd /c \"test_tag.txt\"')\n",
    "os.system('cmd /c \"test1.txt\"')\n",
    "\n",
    "\n",
    "\n",
    "#SCANNING FILE\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.load_model(\"model_final.h5\")\n",
    "mean = 0\n",
    "total = 0\n",
    "twe = get_tweets(var[2], pages = 1)\n",
    "for tweet in twe:\n",
    "    text = tweet['text']\n",
    "    mline = clean_tweet(text)\n",
    "    nline = mline.replace(\",\" , \"\").replace(\".\" , \"\").replace(\")\" , \"\").replace(\"(\" , \"\").replace(\";\" , \"\").replace(\":\" , \"\").replace(\"\\\"\" , \" \").strip().split(\" \")\n",
    "    encode = review_encode(nline)\n",
    "    encode = keras.preprocessing.sequence.pad_sequences([encode],value=word_index[\"<PAD>\"],padding=\"post\",maxlen=250)\n",
    "   \n",
    "    predict = model.predict(encode)\n",
    "    #print(line)\n",
    "    #print(mline)\n",
    "    #print(encode)\n",
    "    #print(predict[0])\n",
    "    mean = ( mean + predict[0])\n",
    "    total = total + 1\n",
    "\n",
    "mean_final = mean / total \n",
    "\n",
    "if mean_final * 100 >= 50 :\n",
    "    print(\"POSITIVE\")\n",
    "    print(mean_final)\n",
    "else :\n",
    "    print(\"Negative\")\n",
    "    print(mean_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}